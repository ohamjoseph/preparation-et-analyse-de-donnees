{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collectes de données\n",
    "Les données utilisées ici ont été collectés via plusieurs sources. D’abord, une archive de tweet `twitter-archive-enhanced.csv` qui nous a été confiée, qu’on a téléchargé et importé dans notre espace de travail. Ensuite, via un lien qui nous a été fourni, nous avons écrit un script qui nous permet d’obtenir automatiquement ce fichier `image-predictions.tsv` et l’enregistrer dans notre espace de travail. Enfin, des données supplémentaires ont étés collectées via l’API de tweeter, ce qui a nécessité la création d’un compte développeur chez tweeter. Ces données sont en format JSON que nous avons enregistré dans un fichier `tweet_json.txt` avant d’extraire les informations qui nous intéressent et les mettre dans un dataframe pandas `df`.\n",
    "# 2. Evaluation des données\n",
    "Les données recueillies à la fin de la collecte de données présentaient des problèmes d’ordre et de qualité, l’évaluation a été fait uniquement sur les tweets qui ne sont pas un retweet et qui ont une image, donc qui sont effectivement des tweets de chien. Grâce aux données contenues dans `twitter-archive-enhanced.csv` et `image-predictions.tsv` nous avons pu effectivement extraire les données qui nous concernent dans un dataframe pandas `original` . Parmi les problèmes d’ordres nous avons relevé deux problèmes concernant les observations. Les trois ensembles de données faisaient cas des mêmes informations, les informations sur les tweets de chien. Nous avons donc fusionné les trois ensembles de données en un seul qui regroupe toutes les informations. Aussi, les types de chiens sont repartis sur plusieurs colonnes. Quant aux problèmes de qualité, nous avons retenues 8. Nous avons entre autres, des problèmes de validité, comme le dénominateur supérieur à 10, de précisions, des noms ou notes de chien incorrect. Et aussi problèmes de catégories, comme le type de la date de publication des tweets.\n",
    "Ils existent bien sûr d’autres problèmes au-delà des ceux dont nous avons fait cas dans notre évaluation.\n",
    "# 3. Nettoyage des données\n",
    "Le nettoyage a été fait par programmation et les outils utilisés sont python et ces bibliothèques pandas, numpy, bs4. Nous avons d’abord fait une copie de nos données originales avec de commencer le nettoyage. Nous avons terminé en enregistrant nos données dans un fichier csv `twitter_archive_master.csv`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
